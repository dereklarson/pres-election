{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "from IPython.display import display\n",
    "from itertools import chain, combinations\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation:\n",
    "  * Load data\n",
    "  * Extract/scale features\n",
    "  * Split into test/train\n",
    "  * Train Model\n",
    "  * Evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data into a single dataframe; votes + chosen census data\n",
    "# Codes: AGE, IPE, RHI, LND, CRM, POP, AGN\n",
    "census_codes = ['AGE', 'IPE', 'RHI', 'LND', 'CRM', 'POP', 'AGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load all of the voting data, filtering null vote counts or missing FIPS codes\n",
    "vote_data = pd.read_csv('Combined_2012_2016_votes.csv').drop(['Unnamed: 0'], axis=1)\n",
    "vote_data = vote_data.loc[vote_data[\"Dem\"] > 0]\n",
    "vote_data = vote_data.loc[vote_data[\"FIPS\"] != 0]\n",
    "\n",
    "# Convert vote data into labels for 2016\n",
    "#full_data = full_data.loc[full_data[\"Year\"] == 2016]\n",
    "votes_2012 = vote_data.loc[vote_data[\"Year\"] == 2012]\n",
    "votes_2016 = vote_data.loc[vote_data[\"Year\"] == 2016]\n",
    "full_data = pd.DataFrame()#votes_2016[[\"FIPS\", \"State\", \"County\"]]\n",
    "full_data['Dfrac_2012'] = votes_2012['Dem'] / votes_2012['Total Votes']\n",
    "full_data['Dfrac_2016'] = votes_2016['Dem'] / votes_2016['Total Votes']\n",
    "\n",
    "\n",
    "#full_data = full_data.drop(['Total Votes', 'Dem', 'Rep', 'Lib', 'Grn'], axis=1)\n",
    "\n",
    "for code in census_codes:\n",
    "    curr_data = pd.read_csv('proc_census_data/{}.csv'.format(code)).drop(['Unnamed: 0'], axis=1)\n",
    "    #full_data = full_data.join(curr_data.set_index(\"FIPS\"), on=[\"FIPS\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dfrac_2012</th>\n",
       "      <th>Dfrac_2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.415674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.265758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.215666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.512523</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262186</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.123478</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.763069</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.460508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.335208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.470608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.217806</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.194505</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.475204</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.456860</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.266566</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.154078</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.248491</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.391888</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.506345</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.417318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dfrac_2012  Dfrac_2016\n",
       "0     0.415674         NaN\n",
       "1     0.265758         NaN\n",
       "2     0.215666         NaN\n",
       "3     0.512523         NaN\n",
       "4     0.262186         NaN\n",
       "5     0.123478         NaN\n",
       "6     0.763069         NaN\n",
       "7     0.460508         NaN\n",
       "8     0.335208         NaN\n",
       "9     0.470608         NaN\n",
       "10    0.217806         NaN\n",
       "11    0.194505         NaN\n",
       "12    0.475204         NaN\n",
       "13    0.456860         NaN\n",
       "14    0.266566         NaN\n",
       "15    0.154078         NaN\n",
       "16    0.248491         NaN\n",
       "17    0.391888         NaN\n",
       "18    0.506345         NaN\n",
       "19    0.417318         NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[:20]#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def column_ratio(df, numerators, denominators, name, to_remove=None):\n",
    "    num = sum([df[col] for col in numerators])\n",
    "    den = sum([df[col] for col in denominators])\n",
    "    df[name] = num / den\n",
    "    if to_remove is None:\n",
    "        to_remove = list(set(numerators + denominators))\n",
    "    df.drop(to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Do some cross-data-type calculations\n",
    "column_ratio(full_data, ['Normalized Cropland - total'], ['Normalized Land area'],\n",
    "             'Agricultural Land Fraction', to_remove=['Normalized Cropland - total'])\n",
    "\n",
    "column_ratio(full_data, ['property crimes'], ['Resident population'], 'property crime rate', to_remove=['property crimes'])\n",
    "\n",
    "full_data['Dfrac'] = full_data['Dem'] / full_data['Total Votes']\n",
    "display(full_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data[full_data['Dfrac'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(df, label_col, method='avg'):\n",
    "    labels = df[label_col].values\n",
    "    if method == 'avg':\n",
    "        predictions = np.ones(len(labels)) * np.mean(labels)\n",
    "    elif method == 'random':\n",
    "        predictions = np.random.uniform(low=0, high=1, size=len(labels))\n",
    "    rmse = np.sqrt(MSE(labels, predictions))\n",
    "    print(\"Baseline model via '{}': {:.5f}\".format(method, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(df, label_col, feature_cols, fold_col=None, n_folds=10):\n",
    "    # Create a numpy.array dataset\n",
    "    if not feature_cols:\n",
    "        return\n",
    "    labels = df[label_col].values\n",
    "    features = df[feature_cols].values\n",
    "    \n",
    "    # Identify how to fold: using a column (e.g. separate by state) or random sample\n",
    "    if not fold_col:\n",
    "        folds = KFold(len(labels), n_folds)\n",
    "    else:\n",
    "        folds = LabelKFold(df[fold_col].values, n_folds)\n",
    "        \n",
    "    pred_row = np.zeros(len(labels))\n",
    "    results = []\n",
    "    for train_idxs, test_idxs in folds:\n",
    "        rfr = RandomForestRegressor()\n",
    "        rfr = rfr.fit(features[train_idxs], labels[train_idxs])\n",
    "        predictions = rfr.predict(features[test_idxs])\n",
    "        pred_row[test_idxs] = predictions\n",
    "        rmse = np.sqrt(MSE(labels[test_idxs], predictions))\n",
    "        results.append(rmse)\n",
    "    df['predictions'] = pred_row\n",
    "    feat_str = ', '.join([feature.replace('Normalized', '')[:8] for feature in feature_cols])\n",
    "    print(\"Performance:  RMSE: {:.4f} +- {:.4f} for {}\".format(np.mean(results), np.std(results), feat_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_sample(df, cols, size=20):\n",
    "    sample = np.random.choice(len(df), size=size)\n",
    "    display(df.iloc[sample][cols])\n",
    "\n",
    "def powerset(iterable, min_ct=0, max_ct=None):\n",
    "    if max_ct is None:\n",
    "        max_ct = len(iterable)\n",
    "    return list(map(list, chain.from_iterable(combinations(list(iterable),n) for n in range(min_ct, max_ct + 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature types | 0: base features, always used, 1: additional features, tested by adding one at a time, 2: unused features \n",
    "features = [(0, 'Asian'),\n",
    "            (0, 'Black'),\n",
    "            (0, 'Hispanic or Latino Origin'),\n",
    "            (0, 'White'),\n",
    "            (0, 'Voting Age Fraction'),\n",
    "            (0, 'Normalized Median Income'),\n",
    "            (0, 'Normalized Land area'),\n",
    "            (0, 'Urban Fraction'),\n",
    "            (0, 'Agricultural Land Fraction'),\n",
    "            (2, 'Poverty Fraction'),\n",
    "            (2, 'property crime rate')\n",
    "           ]\n",
    "base_feature_cols = [feat[1] for feat in features if feat[0] == 0]\n",
    "add_feature_cols = [feat[1] for feat in features if feat[0] == 1]\n",
    "\n",
    "# Try to predict the fraction of democratic voters\n",
    "label_col = 'Dfrac'\n",
    "\n",
    "# Fold by a column to try testing transfer predictability across values of that column (e.g. can a subset of states predict others)\n",
    "fold_columns = [(0, 'State'),\n",
    "                (0, 'FIPS'),\n",
    "                (0, None)\n",
    "                ]\n",
    "\n",
    "fold_col = 'State'\n",
    "fold_col = 'FIPS'\n",
    "fold_col = None\n",
    "sample_cols = [2, 3, 4] + list(range(9, len(full_data.columns)))\n",
    "\n",
    "baseline_model(full_data, label_col)\n",
    "for add_feat_set in powerset(add_feature_cols, min_ct=0, max_ct=1):\n",
    "    for fold_col in [fc[1] for fc in fold_columns if fc[0] == 0]:\n",
    "        print(\"Folding by {}\".format(fold_col))\n",
    "        feature_cols = base_feature_cols + add_feat_set\n",
    "        evaluate_model(full_data, label_col, feature_cols, fold_col)\n",
    "random_sample(full_data, sample_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#full_data.loc[full_data['FIPS'] < 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in Counter(full_data['FIPS'].values).items():\n",
    "    if item[1] > 1:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(map(list, list(powerset(range(4)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
